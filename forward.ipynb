{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfMvRyKSk6puEBI4QtH6TQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YifanLi3/MachineLearningPlayground/blob/main/forward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1piwn4ZZ9rEh",
        "outputId": "88157092-e356-4b77-949d-94357dcb4ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) <dtype: 'float32'> <dtype: 'int32'>\n",
            "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n",
            "batch: (128, 28, 28) (128,)\n",
            "0 0 loss: 0.31987839937210083\n",
            "0 100 loss: 0.20455963909626007\n",
            "0 200 loss: 0.19378912448883057\n",
            "0 300 loss: 0.17524723708629608\n",
            "0 400 loss: 0.19225957989692688\n",
            "1 0 loss: 0.1611412614583969\n",
            "1 100 loss: 0.15502771735191345\n",
            "1 200 loss: 0.15399831533432007\n",
            "1 300 loss: 0.14402303099632263\n",
            "1 400 loss: 0.1568715125322342\n",
            "2 0 loss: 0.13323381543159485\n",
            "2 100 loss: 0.13347411155700684\n",
            "2 200 loss: 0.13260963559150696\n",
            "2 300 loss: 0.1263781487941742\n",
            "2 400 loss: 0.1365147829055786\n",
            "3 0 loss: 0.11666847765445709\n",
            "3 100 loss: 0.12039856612682343\n",
            "3 200 loss: 0.11880874633789062\n",
            "3 300 loss: 0.11503541469573975\n",
            "3 400 loss: 0.12336365878582001\n",
            "4 0 loss: 0.10579782724380493\n",
            "4 100 loss: 0.1114700585603714\n",
            "4 200 loss: 0.10912542045116425\n",
            "4 300 loss: 0.10708081722259521\n",
            "4 400 loss: 0.114107646048069\n",
            "5 0 loss: 0.09806446731090546\n",
            "5 100 loss: 0.10485591739416122\n",
            "5 200 loss: 0.1018151268362999\n",
            "5 300 loss: 0.10106589645147324\n",
            "5 400 loss: 0.1071568951010704\n",
            "6 0 loss: 0.09224508702754974\n",
            "6 100 loss: 0.09966541081666946\n",
            "6 200 loss: 0.09604696184396744\n",
            "6 300 loss: 0.09633897244930267\n",
            "6 400 loss: 0.101640984416008\n",
            "7 0 loss: 0.08772110939025879\n",
            "7 100 loss: 0.09537772089242935\n",
            "7 200 loss: 0.09141142666339874\n",
            "7 300 loss: 0.09244658797979355\n",
            "7 400 loss: 0.0971483364701271\n",
            "8 0 loss: 0.08400758355855942\n",
            "8 100 loss: 0.09184197336435318\n",
            "8 200 loss: 0.08759602159261703\n",
            "8 300 loss: 0.08915027230978012\n",
            "8 400 loss: 0.09341537952423096\n",
            "9 0 loss: 0.08087576925754547\n",
            "9 100 loss: 0.08878730982542038\n",
            "9 200 loss: 0.08434942364692688\n",
            "9 300 loss: 0.08629736304283142\n",
            "9 400 loss: 0.09022393077611923\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# x: [60k, 28, 28]\n",
        "# y: [60k]\n",
        "(x, y), _ = mnist.load_data()\n",
        "\n",
        "# x: [0 ~ 255] --> [0 ~ 1.] after / 255.\n",
        "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
        "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
        "print (x.shape, y.shape, x.dtype, y.dtype)\n",
        "\n",
        "# x: 0 ~ 255 before nomalization\n",
        "# y: 0 ~ 9\n",
        "print (tf.reduce_min(x), tf.reduce_max(x))\n",
        "print (tf.reduce_min(y), tf.reduce_max(y))\n",
        "\n",
        "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
        "train_iter = iter(train_db)\n",
        "sample = next(train_iter)\n",
        "print ('batch:', sample[0].shape, sample[1].shape)\n",
        "\n",
        "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
        "b1 = tf.Variable(tf.zeros([256]))\n",
        "\n",
        "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
        "b2 = tf.Variable(tf.zeros([128]))\n",
        "\n",
        "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
        "b3 = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "lr = 0.001\n",
        "for epoch in range(10):\n",
        "  for step, (x, y) in enumerate(train_db):\n",
        "    # x: [128, 28, 28]\n",
        "    # y: [128]\n",
        "    # [b, 28, 28] --> [b, 28*28]\n",
        "    x = tf.reshape(x, [-1, 28*28])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # h1 = x@w1+b1\n",
        "      h1 = x@w1 + tf.broadcast_to(b1, (x.shape[0], 256))\n",
        "      h1 = tf.nn.relu(h1)\n",
        "      h2 = h1@w2 + b2\n",
        "      h2 = tf.nn.relu(h2)\n",
        "      out = h2@w3 + b3\n",
        "\n",
        "      #compute loss\n",
        "      y_onehot = tf.one_hot(y, depth=10)\n",
        "\n",
        "      loss = tf.square(y_onehot - out)\n",
        "      loss = tf.reduce_mean(loss)\n",
        "\n",
        "    grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
        "    # w1 = w1 - lr * w1_grad\n",
        "    w1.assign_sub(lr * grads[0])\n",
        "    b1.assign_sub(lr * grads[1])\n",
        "    w2.assign_sub(lr * grads[2])\n",
        "    b2.assign_sub(lr * grads[3])\n",
        "    w3.assign_sub(lr * grads[4])\n",
        "    b3.assign_sub(lr * grads[5])\n",
        "    #w1 = tf.Variable(w1 - lr * grads[0])\n",
        "    #b1 = tf.Variable(b1 - lr * grads[1])\n",
        "    #w2 = tf.Variable(w2 - lr * grads[2])\n",
        "    #b2 = tf.Variable(b2 - lr * grads[3])\n",
        "    #w3 = tf.Variable(w3 - lr * grads[4])\n",
        "    #b3 = tf.Variable(b3 - lr * grads[5])\n",
        "\n",
        "    if step % 100 == 0:\n",
        "      print(epoch, step, 'loss:', float(loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P96FzdAB-LJj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}