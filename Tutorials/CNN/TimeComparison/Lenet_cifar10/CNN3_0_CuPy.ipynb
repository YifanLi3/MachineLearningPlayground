{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk82Ki1IIEJi"
      },
      "source": [
        "# Includes Channel and Batch\n",
        "\n",
        "Coded by Lujia Zhong @lujiazho"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lujiazho/MachineLearningPlayground.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgTzTXTGIIA8",
        "outputId": "02142c85-2699-46fe-8f15-c97c11d25818"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MachineLearningPlayground'...\n",
            "remote: Enumerating objects: 234, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 234 (delta 69), reused 118 (delta 38), pack-reused 65\u001b[K\n",
            "Receiving objects: 100% (234/234), 25.36 MiB | 9.91 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MachineLearningPlayground/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUvzE3k-IUzi",
        "outputId": "2185491b-e309-4544-d4ab-ccebe2465372"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MachineLearningPlayground\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PB40VZO5IEJo"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pickle\n",
        "import cupy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from miniml.ann import *\n",
        "from miniml.ann.common import *\n",
        "from miniml.ann.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9T39JPu1IEJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e59a539-e9c1-47b4-fbe3-788c58445ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "with open('../data_batch_1', 'rb') as fo:\n",
        "    dict_ = pickle.load(fo, encoding='bytes')\n",
        "with open('../batches.meta', 'rb') as fo:\n",
        "    meta = pickle.load(fo, encoding='bytes')\n",
        "\n",
        "data, labels = dict_[b'data'], dict_[b'labels']\n",
        "names = meta[b'label_names']\n",
        "len(data), len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yNeoLDKAIEJt",
        "outputId": "8f62f0a4-e80a-4a13-ae14-d7ffec5137a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'ship'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "idx = 100\n",
        "img = data[idx].reshape(3,32,32)\n",
        "print(names[labels[idx]])\n",
        "_ = plt.imshow(img.transpose(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "viMKBCy9IEJv"
      },
      "outputs": [],
      "source": [
        "class Conv2D(Node):\n",
        "    def __init__(self, nodes, weights, bias, output_c, input_c, stride=1, padding=False):\n",
        "        self.output_c = output_c\n",
        "        self.input_c = input_c\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.bias = True if bias else False\n",
        "        Node.__init__(self, [nodes, weights, bias] if bias else [nodes, weights])\n",
        "\n",
        "    def conv_(self, n_c, n_h, n_w, img, filter_, s=1):\n",
        "        k = filter_.shape[2]\n",
        "        res = np.zeros((self.inputs[0].value.shape[0], n_c, n_h, n_w))\n",
        "        aug = np.repeat(img, filter_.shape[0], axis=0)\n",
        "        aug = aug.reshape(img.shape[0], filter_.shape[0], img.shape[1], img.shape[2], img.shape[3])\n",
        "        for i in range(n_h):\n",
        "            for j in range(n_w):\n",
        "                res[:,:,i,j] = np.sum(aug[:,:,:,i*s:i*s+k,j*s:j*s+k]*filter_, axis=(2,3,4))\n",
        "        return res\n",
        "        \n",
        "    def forward(self):\n",
        "        # inputs: [batch, channel_in, hight_in, width_in]\n",
        "        inputs = self.inputs[0].value\n",
        "        # weights: [channel_out, channel_in, kernel_size, kernel_size]\n",
        "        weights = self.inputs[1].value\n",
        "        # bias: [channel_out, 1, 1] or [1, channel_out, 1, 1] is the same\n",
        "        if self.bias:\n",
        "            bias = self.inputs[2].value\n",
        "        k = weights.shape[2]  # kernel size (w equals to h)\n",
        "\n",
        "        s = self.stride\n",
        "        if self.padding:\n",
        "            inputs = np.pad(inputs, ((0,0),(0,0),(k//2,k//2),(k//2,k//2)), 'constant')\n",
        "        assert (inputs.shape[2]-k)%s == 0\n",
        "        assert (inputs.shape[3]-k)%s == 0\n",
        "        assert s < k\n",
        "\n",
        "        n_c = self.output_c\n",
        "        new_h = (inputs.shape[2]-k)//s+1\n",
        "        new_w = (inputs.shape[3]-k)//s+1\n",
        "\n",
        "        # value: [batch, channel_out, hight_out, width_out]\n",
        "        self.value = self.conv_(n_c, new_h, new_w, inputs, weights, s=s) + (bias if self.bias else 0)\n",
        "    \n",
        "    def backward(self):\n",
        "        # create zero loss for all inputs\n",
        "        self.gradients = {n: np.zeros_like(n.value, dtype=np.float64) for n in self.inputs}\n",
        "        s = self.stride\n",
        "        k = self.inputs[1].value.shape[2]\n",
        "        X = self.inputs[0].value\n",
        "\n",
        "        for n in self.outputs:\n",
        "            # Get the cost w.r.t this node.\n",
        "            grad_y = n.gradients[self]\n",
        "            \n",
        "            # calculate inserted gradient_y\n",
        "            if s > 1:\n",
        "                tmp = np.insert(grad_y.reshape(grad_y.shape[0],grad_y.shape[1],-1,1), 1, [[[[0]]]]*(s-1), axis=3)\n",
        "                tmp = tmp.reshape(grad_y.shape[0],grad_y.shape[1],grad_y.shape[2],-1)[:,:,:,:-(s-1)]\n",
        "                tmp = np.insert(tmp, np.repeat(range(1,grad_y.shape[2]), (s-1)), [0]*tmp.shape[3], axis=2)\n",
        "                inser_grad = np.pad(tmp, ((0,0),(0,0),(k-1,k-1),(k-1,k-1)), 'constant')\n",
        "            else:\n",
        "                inser_grad = np.pad(grad_y, ((0,0),(0,0),(k-1,k-1),(k-1,k-1)), 'constant')\n",
        "            \n",
        "            # W: [ch_out, ch_in, kernel_size, kernel_size], rotate 2 times in h and w dimension\n",
        "            rotated_w = np.rot90(self.inputs[1].value, 2, axes=(2,3))\n",
        "            \n",
        "            # X: [batch, ch_in, height_in, width_in]\n",
        "            n_h = self.gradients[self.inputs[0]].shape[2]\n",
        "            n_w = self.gradients[self.inputs[0]].shape[3]\n",
        "\n",
        "            # A special but useful trick to calculate all together\n",
        "            aug1 = np.repeat(inser_grad, rotated_w.shape[1], axis=1)\n",
        "            aug1 = aug1.reshape(inser_grad.shape[0], inser_grad.shape[1], \n",
        "                                rotated_w.shape[1], inser_grad.shape[2], inser_grad.shape[3])\n",
        "            aug2 = np.repeat(rotated_w, aug1.shape[1], axis=0)\n",
        "            aug2 = aug2.reshape(rotated_w.shape[0], aug1.shape[1], \n",
        "                                rotated_w.shape[1], rotated_w.shape[2], rotated_w.shape[3])\n",
        "            re_aug1 = np.repeat(aug1, aug2.shape[0], axis=0)\n",
        "            re_aug1 = re_aug1.reshape(aug1.shape[0], aug2.shape[0], \n",
        "                                aug1.shape[1], aug1.shape[2], aug1.shape[3], aug1.shape[4])\n",
        "\n",
        "            grad_X = np.zeros_like(X, dtype=np.float64)\n",
        "            for i in range(n_h):\n",
        "                for j in range(n_w):\n",
        "                    # dim 0 for batch, dim 1 and 2 for ch_out, dim 3 for ch_in, dim 4 and 5 for h&w\n",
        "                    grad_X[:,:,i,j] = np.sum(re_aug1[:,:,:,:,i:i+k,j:j+k]*aug2, axis=(1,2,4,5))\n",
        "            self.gradients[self.inputs[0]] += grad_X\n",
        "            \n",
        "            # W: [ch_out, ch_in, kernel_size, kernel_size]\n",
        "            aug1 = np.repeat(inser_grad, X.shape[1], axis=1)\n",
        "            aug1 = aug1.reshape(inser_grad.shape[0], inser_grad.shape[1], X.shape[1],\n",
        "                                inser_grad.shape[2], inser_grad.shape[3])\n",
        "            aug2 = np.repeat(X, aug1.shape[1], axis=0)\n",
        "            aug2 = aug2.reshape(X.shape[0], aug1.shape[1], X.shape[1], X.shape[2], X.shape[3])\n",
        "            re_aug1 = np.repeat(aug1, aug2.shape[0], axis=0)\n",
        "            re_aug1 = re_aug1.reshape(aug1.shape[0], aug2.shape[0], \n",
        "                                aug1.shape[1], aug1.shape[2], aug1.shape[3], aug1.shape[4])\n",
        "            \n",
        "            grad_W = np.zeros_like(self.inputs[1].value, dtype=np.float64)\n",
        "            \n",
        "            for i in range(grad_W.shape[2]):\n",
        "                for j in range(grad_W.shape[3]):\n",
        "                    # dim 0 and 1 are for batch, 4 and 5 are for h and w, 2 and 3 are for ch_out and ch_in\n",
        "                    grad_W[:,:,i,j] = np.sum(re_aug1[:,:,:,:,i:i+X.shape[2],j:j+X.shape[3]]*aug2, axis=(0,1,4,5))\n",
        "            self.gradients[self.inputs[1]] += np.rot90(grad_W, 2, axes=(2,3))\n",
        "            \n",
        "            if self.bias:\n",
        "                self.gradients[self.inputs[2]] += np.sum(grad_y, \n",
        "                                                         axis=(0,2,3), \n",
        "                                                         keepdims=False).reshape(grad_y.shape[1],1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ogd1Qw6YIEJz"
      },
      "outputs": [],
      "source": [
        "class AvePooling(Node):\n",
        "    def __init__(self, nodes, k=3):\n",
        "        self.k = k\n",
        "        Node.__init__(self, [nodes])\n",
        "\n",
        "    def conv_(self, n_c, n_h, n_w, img, filter_, s=1):\n",
        "        k = self.k\n",
        "        res = np.zeros((self.inputs[0].value.shape[0], n_c, n_h, n_w))\n",
        "        for i in range(n_h):\n",
        "            for j in range(n_w):\n",
        "                res[:,:,i,j] = np.sum(img[:,:,i*s:i*s+k,j*s:j*s+k]*filter_, axis=(2,3))\n",
        "        return res\n",
        "        \n",
        "    def forward(self):\n",
        "        inputs = self.inputs[0].value\n",
        "        k = self.k\n",
        "        \n",
        "        assert inputs.shape[2]%k == 0\n",
        "        assert inputs.shape[3]%k == 0\n",
        "        assert k > 1\n",
        "\n",
        "        filter_ = np.ones((k, k))/(k*k)\n",
        "        new_h = inputs.shape[2]//k\n",
        "        new_w = inputs.shape[3]//k\n",
        "        \n",
        "        self.value = self.conv_(inputs.shape[1], new_h, new_w, inputs, filter_, s=k)\n",
        "    \n",
        "    def backward(self):\n",
        "        # create zero loss for all inputs\n",
        "        self.gradients = {n: np.zeros_like(n.value, dtype=np.float64) for n in self.inputs}\n",
        "        s = k = self.k\n",
        "        X = self.inputs[0].value\n",
        "\n",
        "        for n in self.outputs:\n",
        "            # Get the cost w.r.t this node.\n",
        "            grad_y = n.gradients[self]\n",
        "\n",
        "            tmp = np.insert(grad_y.reshape(grad_y.shape[0],grad_y.shape[1],-1,1), 1, [[[[0]]]]*(s-1), axis=3)\n",
        "            tmp = tmp.reshape(grad_y.shape[0],grad_y.shape[1],grad_y.shape[2],-1)[:,:,:,:-(s-1)]\n",
        "            tmp = np.insert(tmp, np.repeat(range(1,grad_y.shape[2]), (s-1)), [0]*tmp.shape[3], axis=2)\n",
        "            inser_grad = np.pad(tmp, ((0,0),(0,0),(k-1,k-1),(k-1,k-1)), 'constant')\n",
        "            \n",
        "            w = np.ones((k, k))/(k*k)\n",
        "            \n",
        "            n_h = self.gradients[self.inputs[0]].shape[2]\n",
        "            n_w = self.gradients[self.inputs[0]].shape[3]\n",
        "            self.gradients[self.inputs[0]] += self.conv_(X.shape[1], n_h, n_w, inser_grad, w, s=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZKuoGfzAIEJ1"
      },
      "outputs": [],
      "source": [
        "class Flatten(Node):\n",
        "    def __init__(self, nodes):\n",
        "        Node.__init__(self, [nodes])\n",
        "        \n",
        "    def forward(self):\n",
        "        inputs = self.inputs[0].value\n",
        "        self.value = inputs.flatten().reshape(inputs.shape[0],-1)\n",
        "    \n",
        "    def backward(self):\n",
        "        # create zero loss for all inputs\n",
        "        self.gradients = {n: np.zeros_like(n.value, dtype=np.float64) for n in self.inputs}\n",
        "        X = self.inputs[0].value\n",
        "\n",
        "        for n in self.outputs:\n",
        "            # Get the cost w.r.t this node.\n",
        "            grad_cost = n.gradients[self]\n",
        "            self.gradients[self.inputs[0]] += grad_cost.reshape(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z10_fQmJIEJ2"
      },
      "outputs": [],
      "source": [
        "W1 = np.random.randn(6, 3, 5, 5)\n",
        "b1 = np.random.randn(6, 1, 1)\n",
        "\n",
        "W2 = np.random.randn(16, 6, 5, 5)\n",
        "b2 = np.random.randn(16, 1, 1)\n",
        "\n",
        "W3 = np.random.randn(400, 120)\n",
        "b3 = np.random.randn(120)\n",
        "\n",
        "W4 = np.random.randn(120, 84)\n",
        "b4 = np.random.randn(84)\n",
        "\n",
        "W5 = np.random.randn(84, 10)\n",
        "\n",
        "x_node, y_node = Placeholder(), Placeholder()\n",
        "\n",
        "W1_node = Placeholder()\n",
        "b1_node = Placeholder()\n",
        "\n",
        "W2_node = Placeholder()\n",
        "b2_node = Placeholder()\n",
        "\n",
        "W3_node = Placeholder()\n",
        "b3_node = Placeholder()\n",
        "\n",
        "W4_node = Placeholder()\n",
        "b4_node = Placeholder()\n",
        "\n",
        "W5_node = Placeholder()\n",
        "\n",
        "conv1 = Conv2D(x_node, W1_node, b1_node, output_c=6, input_c=3, stride=1, padding=False)\n",
        "ave1 = AvePooling(conv1, k=2)\n",
        "conv2 = Conv2D(ave1, W2_node, b2_node, output_c=16, input_c=6, stride=1, padding=False)\n",
        "ave2 = AvePooling(conv2, k=2)\n",
        "flat = Flatten(ave2)\n",
        "l1 = Linear(flat, W3_node, b3_node)\n",
        "sigmoid1 = Sigmoid(l1)\n",
        "l2 = Linear(sigmoid1, W4_node, b4_node)\n",
        "sigmoid2 = Sigmoid(l2)\n",
        "l3 = Linear(sigmoid2, W5_node, None)\n",
        "sigmoid3 = Sigmoid(l3)\n",
        "mse = MSE(y_node, sigmoid3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-HJYj_0oIEJ3"
      },
      "outputs": [],
      "source": [
        "feed_dict = {\n",
        "    x_node: np.array([img]),\n",
        "    y_node: np.array([0,1,0,0,0,0,0,0,0,0]),\n",
        "\n",
        "    W1_node: W1,\n",
        "    b1_node: b1,\n",
        "\n",
        "    W2_node: W2,\n",
        "    b2_node: b2,\n",
        "    \n",
        "    W3_node: W3,\n",
        "    b3_node: b3,\n",
        "    \n",
        "    W4_node: W4,\n",
        "    b4_node: b4,\n",
        "    \n",
        "    W5_node: W5\n",
        "}\n",
        "\n",
        "graph = feed_dict_2_graph(feed_dict)    # network graph\n",
        "sorted_graph = topology(graph)          # sorted graph\n",
        "trainables = [W1_node, b1_node, W2_node, b2_node, W3_node, b3_node, W4_node, b4_node, W5_node]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PknToxUlIEJ5",
        "outputId": "f55f3ac5-d114-4322-eb02-4caf4e6685dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.1635\n",
            "Epoch: 2, Loss: 0.0998\n",
            "Epoch: 3, Loss: 0.0992\n",
            "Epoch: 4, Loss: 0.0995\n",
            "Epoch: 5, Loss: 0.0958\n",
            "Epoch: 6, Loss: 0.0941\n",
            "Epoch: 7, Loss: 0.0925\n",
            "Epoch: 8, Loss: 0.0897\n",
            "Epoch: 9, Loss: 0.0871\n",
            "Epoch: 10, Loss: 0.0848\n",
            "Epoch: 11, Loss: 0.0826\n",
            "Epoch: 12, Loss: 0.0801\n",
            "Epoch: 13, Loss: 0.0784\n",
            "Epoch: 14, Loss: 0.0769\n",
            "Epoch: 15, Loss: 0.0754\n",
            "Epoch: 16, Loss: 0.0737\n",
            "Epoch: 17, Loss: 0.0721\n",
            "Epoch: 18, Loss: 0.0705\n",
            "Epoch: 19, Loss: 0.0689\n",
            "Epoch: 20, Loss: 0.0671\n",
            "11.9857 sec/epoch\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "optimizer = 'Adam'\n",
        "lr = 1e-2\n",
        "epochs = 20\n",
        "batch = 2\n",
        "\n",
        "# only used for Adam\n",
        "it = 0\n",
        "\n",
        "for i in range(1, epochs+1):\n",
        "    it += 1\n",
        "    losses = []\n",
        "    for j in range(1, 100, batch):\n",
        "        # Step 4.1: sample a batch of examples and Reset value\n",
        "        x_node.value = data[j:j+batch].reshape(batch, 3, 32, 32)\n",
        "        y_node.value = np.eye(10)[labels[j:j+batch]].reshape(batch,-1)\n",
        "\n",
        "        # Step 4.2: forward\n",
        "        for n in sorted_graph:\n",
        "            n.forward()\n",
        "\n",
        "        # Step 4.3: backward\n",
        "        for n in sorted_graph[::-1]:\n",
        "            n.backward()\n",
        "\n",
        "        # Step 4.4: optimization\n",
        "        for t in trainables:\n",
        "            t.optimize(optimizer=optimizer, lr=lr, it=it)\n",
        "\n",
        "        # Step 5: update current loss\n",
        "        loss = sorted_graph[-1].value\n",
        "        \n",
        "        losses.append(loss)\n",
        "\n",
        "    if (i+1) % 1 == 0:\n",
        "        print(\"Epoch: {}, Loss: {:.4f}\".format(i, np.mean(losses)))\n",
        "print(f\"{((time.time() - start_time)/epochs):.4f} sec/epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JcPtg8qBIEJ6",
        "outputId": "e433d2fc-d866-4cfe-cbf2-91f1ff51a95f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.156\n"
          ]
        }
      ],
      "source": [
        "preds = []\n",
        "reals = []\n",
        "for i in range(1):\n",
        "    x_node.value = np.array(data[i:i+1000]).reshape(1000, 3, 32, 32)\n",
        "    for n in sorted_graph[:-1]:\n",
        "        n.forward()\n",
        "    preds.append(np.argmax(sorted_graph[-2].value, axis=1))\n",
        "    reals.append(labels[i:i+1000])\n",
        "print(np.sum(np.array(preds)==np.array(reals))/1000)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "CNN3.0_CuPy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}